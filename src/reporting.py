# %%
import os
import sys
from datetime import datetime
from pathlib import Path

import missingno as msno
import numpy as np

import etl_pipeline as etl

# %%
timestr = datetime.now().strftime("%Y_%m_%d")


# %%
def print_column_info(df):
    """[summary] pretty prints pandas dataframe data.
    Doesn't need a return statemnet.
    Args:
        df ([type]): [description]
    """
    template = "%-8s %-30s %s"
    print(template % ("Type", "Column Name", "Example Value"))
    print("-"*53)
    # TODO - makes sure it returns valid entires for examples.
    for c in df.columns:
        print(template % (df[c].dtype, c, df[c].iloc[1]))


# %%
def nodes_error_reporting(gdf, test_name, failed_nodes):
    """[Returns float indicating the total number of nodes failing a given test.]

    Arguments:
        gdf {[geopandasdataframe]} -- [the master naptan dataframe]
        testName {[str]} -- [name of the given test that called this method.]
        failed_nodes {[pandas dataframe]} -- [the failed node dataframe
        generated by the check been performed is passed to the report.]
        total_nodes {[int]} -- [The total number of naptan nodes.]
    Returns:
        [Error report files] -- [A percentage figure.]
    """
    total_nodes = len(gdf)
    result = (len(failed_nodes) / total_nodes)
    error_percent = (f""" {timestr},"""
                     f"""Check {test_name} contains {len(failed_nodes)},"""
                     f""" failed nodes. {result:0.3f}% of all Naptan, """
                     f""" {len(failed_nodes)} nodes failed this check.""")
    report_folder = f"Downloads/Naptan_Error_Reports/{timestr}/"
    error_dir = Path(os.path.join(Path.home(), report_folder))
    report_file = Path(error_dir, f'{test_name}_Warnings.csv')
    node_stats = Path(error_dir, 'Failed_Check_Stats.csv')

    try:
        if not error_dir.exists():
            Path(f'{error_dir}').mkdir(parents=True,
                                       exist_ok=True)
            print(f"{error_dir} error folder has being created.")

    except ZeroDivisionError as zero:
        raise (f'{zero}')
        sys.exit('The chosen area has not returned any failing naptan nodes.')

    except FileExistsError:
        print(f'The {timestr} report file has been created.')

    except Exception as e:
        raise e
        sys.exit(f'{e} Report creation failed')

    finally:
        with open(node_stats, 'a+') as text_file:
            print(error_percent, file=text_file)

        with open(report_file, 'a+') as f:
            failed_nodes.to_csv(f,
                                index=False,
                                encoding='utf-8',
                                header=f.tell() == 0)


# %%
def plot_missing_data(df, sample_rate):
    """[summary]

    Args:
        df ([type]): [description]
        sample_rate ([type]): [description]

    Returns:
        [type]: [description]
    """
    fig = msno.matrix(df.sample(sample_rate))
    plot = fig.get_figure()
    # plot = fig.savefig('Missing Data Matrix.png')
    # fig.save_figure(format='bmp')
    return plot


# %% 
def visualise_missing_counts(df, sample_rate):
    """[summary] Provides a visualise matrix view and bar chart of missing 
    naptan values.  Creates a null data map of naptan geodata, using missing no.

    Raises:
        e: [description]

    Returns:
        [type] -- [description]
    """
    # TODO -> return this data as an output.
    dfcol = list(df.columns.values)
    output = []
    for i in dfcol:
        # write column length. 
        output.append(len(df[i]))
        output.append(len(df[i].unique()))
        # count nan/nulls
        nullvalues = df.isnull().sum(axis=0)
        # count of zero values
        zerovalues = df[df == 0].count(axis=0)
        # get percentage of nan rows.
        percent_nan = (df[i].isna().mean().round(4) * 100)
        #print(nullvalues, zerovalues, percent_nan)
        nullDataMap = msno.matrix(df.sample(sample_rate))
        #nullDataMap.save_figure(format='.bmp')
    return nullDataMap


# %%
def list_unique_values(df, column_name):
    """[summary]  takes a dataframe and returns a listing the unique values
    therein.
    Returns:
        [list] -- [description]
    """
    lst = df[column_name].drop_duplicates()
    df_col_unique = lst.tolist()
    return df_col_unique
